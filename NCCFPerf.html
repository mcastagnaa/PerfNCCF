<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Retail funds performance and Net Client Cash-Flows: a data based analysis</title>

<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 12px;
   margin: 8px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 { 
   font-size:2.2em; 
}

h2 { 
   font-size:1.8em; 
}

h3 { 
   font-size:1.4em; 
}

h4 { 
   font-size:1.0em; 
}

h5 { 
   font-size:0.9em; 
}

h6 { 
   font-size:0.8em; 
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre {	
   margin-top: 0;
   max-width: 95%;
   border: 1px solid #ccc;
   white-space: pre-wrap;
}

pre code {
   display: block; padding: 0.5em;
}

code.r, code.cpp {
   background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * { 
      background: transparent !important; 
      color: black !important; 
      filter:none !important; 
      -ms-filter: none !important; 
   }

   body { 
      font-size:12pt; 
      max-width:100%; 
   }
       
   a, a:visited { 
      text-decoration: underline; 
   }

   hr { 
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote { 
      padding-right: 1em; 
      page-break-inside: avoid; 
   }

   tr, img { 
      page-break-inside: avoid; 
   }

   img { 
      max-width: 100% !important; 
   }

   @page :left { 
      margin: 15mm 20mm 15mm 10mm; 
   }
     
   @page :right { 
      margin: 15mm 10mm 15mm 20mm; 
   }

   p, h2, h3 { 
      orphans: 3; widows: 3; 
   }

   h2, h3 { 
      page-break-after: avoid; 
   }
}

</style>



<!-- MathJax scripts -->
<script type="text/javascript" src="https://c328740.ssl.cf1.rackcdn.com/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



</head>

<body>
<h1>Retail funds performance and Net Client Cash-Flows: a data based analysis</h1>

<p><em>Matteo Castagna (Nov/2013) - OMGI Investment Risk &amp; Performance / v.1.1</em></p>

<blockquote>
<p>This paper has been created entirely with <em>R</em> language and environment (a GNU project - available as Free Software).<br/>
Raw data are stored and retrieved from a SQLServer dBase. The added <em>R</em> packages used are listed below.<br/>
The entire analysis is reproducible and embedded in the paper itself at runtime.<br/>
All the relevant material is available as a Git repo at <a href="https://githib.com/mcastagnaa/PerfNCCF">https://githib.com/mcastagnaa/PerfNCCF</a>  </p>
</blockquote>

<pre><code class="r results=&#39;hide&#39;,message=FALSE">library(ggplot2)
library(knitr)
library(scales)
library(car)
library(grid)
library(gridExtra)
library(zoo)
library(bdsmatrix)
library(nlme)
library(Formula)
library(MASS)
library(sandwich)
library(plm)
</code></pre>

<h3>Introduction and summary</h3>

<p>A large portion of our time is spent analysing and making sure funds perform &ldquo;well&rdquo;. But are fund performances a key factor determining their success? Or is it something else driving it?</p>

<p>My starting point is that a commercially successful product is a product that sells. A fund that performs well (however you want to measure this: in absolute terms, vs. a reference index or vs. peer group) but doesn&#39;t sell is not a success. </p>

<p>The objective of an asset management company is to sell as many of their fund as they can using scalable operations (i.e. without incurring in excess operational costs).</p>

<p>Sure there are management fees that needs to be accounted for as well; but the focus of this analysis are retail products, not mandates or Hedge Funds.
Retail products only rarely command performance fees. </p>

<p>This papers demonstrate that there is a very weak statistical relationship between a fund performance and the net client cash-flows (NCCF - the difference between subscriptions and redemptions).
That is: there is no clear relationship between the fund manager success in terms of fund returns (using all possible different measures) and its commercial success (as measured by the increase of AuMs).</p>

<h3>Method</h3>

<p>The <em>IR&amp;P</em> team has developed a substantial dataset that enable proper data analysis: this paper is based on two data panels:</p>

<ul>
<li><p>Panel A - covering the entire set of OMGI funds/mandates over the last 10 months (Jan/2013 to Oct/2013) </p>

<pre><code class="r, echo=FALSE, comment=&quot;&quot;">load(&quot;OMGIset.Rda&quot;)
colnames(rawdata)[names(rawdata) == &quot;NCCFEstimate&quot;] &lt;- &quot;NCCF&quot;
rawdata$RefDate &lt;- as.Date(rawdata$RefDate)
print(paste0(&quot;Raw number of products: &quot;,
         as.character(length(unique(rawdata$FundCode)))))
print(paste0(&quot;Observations: &quot;,
         as.character(length(rawdata$FundCode))))
</code></pre></li>
<li><p>Panel B - considering the bigger OMGI retail funds alongside up to 7 competitors (as defined by the <em>Product</em> unit) and &ldquo;two best-sellers&rdquo; (over the last 1m and 3m , as sourced from Morningstar). This is observed between Apr/2013 and Oct/2013. </p></li>
</ul>

<pre><code class="r, echo=FALSE, comment=&quot;&quot;">load(&quot;COMPset.Rda&quot;)

#add variable
compdata$ItemType &lt;- compdata$ItemId
compdata$ItemType &lt;- sub(&quot;Comp.&quot;, &quot;Competitor&quot;, compdata$ItemType)
compdata$ItemType &lt;- sub(&quot;BS&quot;, &quot;BestSeller&quot;, compdata$ItemType)
compdata$RefDate &lt;- as.Date(compdata$RefDate)
print(paste0(&quot;Raw number of products: &quot;,
             as.character(length(unique(compdata$FundId)))))
print(paste0(&quot;Observations: &quot;,
             as.character(length(compdata$FundId))))

</code></pre>

<p>Panel A is used to analyse the impact of different measures of performance on the monthly NCCF. 
The performance measures used are</p>

<ul>
<li>absolute </li>
<li>relative</li>
<li>sector percentile ranking 
over 1m, 3m, 6m, 1y, 2y, 3y. 
The analysis considered as well the 1m and 3m lagged performance variables by 1, 2, and 3 periods (that is the effect on NCCF from the performance variables observed 1, 2 and 3 months before).
When more data will be available further lags will be considered.</li>
</ul>

<p>Panel B is used to assess how important is the 1y and 3y relative performance (relative to the best sellers) and volatility of returns to explain the 1 or 3 months NCCF ratio vs. the best seller NCCF in the peer group.
Using Panel B enables us to explore beyond the OMGI world.</p>

<h4>Panel A data management</h4>

<p>The raw dataset for Panel A consists in official performance data (as collected on a monthly basis from Morningstar) and NCCF estimates computed by <em>IR&amp;P</em> based on the following: </p>

<p>\[ 
NCCF(t) = \frac{NCCF_i(t-1, t)}{AuM_i(t-1)} =\left(\frac{AuM_i(t)}{AuM_i(t-1)} - 1\right) - {Perf_i(t-1, t)}
 \] </p>

<p>that is the percent change of AuMs for the product <em>i</em> between <em>t-1</em> and <em>t</em> due to only to subscriptions and redemptions is equal to the percentage change of the fund AuMs less the fund performance over the same period.
What we are doing with that measure is to get rid of the increase of AuM due to the performance of the fund itself which is liked to the market movements and/or <em>alpha</em> delivered by the activity of the fund manager.</p>

<p>Few tweaks are applied to the dataset in order to get rid of outliers (notably the SKPROP fund is showing wild performance swings because of a) how the fund is priced and b) how difficult is to get hold of the benchmark data) and observations belonging to products not actually marketed (i.e. using seed capital).</p>

<pre><code class="r echo=FALSE, comment=&quot;&quot;">NCCFtolerance &lt;- 0.5
print(paste0(&quot;Outliers with |NCCF| &gt; &quot;, 
            as.character(NCCFtolerance*100), &quot;%: &quot; ,
            sum(rawdata$NCCF &gt; NCCFtolerance |  
                  rawdata$NCCF &lt; -NCCFtolerance, na.rm = TRUE)))
panelA &lt;- rawdata[rawdata$NCCF &lt; NCCFtolerance &amp; 
                    rawdata$NCCF &gt; -NCCFtolerance, ]

ExcludeFunds &lt;- c(&quot;SKPROP&quot;)
print(paste0(&quot;Excluded funds: &quot;, ExcludeFunds))
print(paste0(&quot;Excluded observations from excluded funds: &quot;, 
             as.character(sum(panelA$FundCode %in% ExcludeFunds, na.rm=TRUE))))
panelA &lt;- panelA[! panelA$FundCode %in% ExcludeFunds, ]
#exclude Select seeded

#summary(panelA$IsSelect)
print(paste0(&quot;Seeded Select funds obs.: &quot;, 
             as.character(sum(panelA$IsSelect == 1, na.rm=TRUE))))
panelA &lt;- panelA[! panelA$IsSelect == 1, ]
print(paste0(&quot;Final number of products: &quot;,
             as.character(length(unique(panelA$FundCode)))))

print(paste0(&quot;Final number of observations: &quot;,
             as.character(length(panelA$FundCode))))

</code></pre>

<p>The end result is the data set for panel A used for numerical and graphical analysis.</p>

<p>The distribution of the NCCF in the sample is as follows:</p>

<pre><code class="r echo =FALSE, fig.width=6, fig.height=6">hist(panelA$NCCF, prob = TRUE)
curve(dnorm(x, mean = mean(panelA$NCCF, na.rm = TRUE), 
            sd = sd(panelA$NCCF, na.rm = TRUE)), 
      add=TRUE, col = &quot;red&quot;)

</code></pre>

<h4>Panel B data management</h4>

<p>Data are again sourced from Morningstar and the criteria for their collection is based on the definition of a restricted set of competitors for the relevant OMGI funds as defined by the <em>Products</em> unit.
The focus in this case is about assessing how the performance-NCCF relationship works outside the OMGI set of products.
NCCF is now provided by Morningstar and it&#39;s not based on <em>IR&amp;P</em> estimates.
The basic dataset is the same as the one used for the regular monthly updates</p>

<pre><code class="r echo = FALSE, fig.width=10, fig.height=8">bubexset &lt;- compdata[compdata$FundId == 314 &amp; 
                       as.Date(compdata$RefDate) == as.Date(&#39;2013-10-31&#39;),]

ggplot(bubexset, aes(Perf3y, 
                     NCCF3mGBPmn,
                     size = StDev3y, 
                     label=ItemId)) +
  geom_point(aes(colour = ItemType)) +
  geom_text(size=3) +
  xlab(&quot;Performance 3y (annualized)&quot;) + ylab(&quot;NCCF 3m (GBP mn)&quot;) +
  labs(title = bubexset[bubexset$ItemId == &#39;OMGI&#39;, &quot;FundName&quot;]) + 
  theme(plot.title = element_text(face = &quot;bold&quot;)) +
  scale_colour_manual(values = c(&quot;red&quot;,&quot;orange&quot;, &quot;cyan&quot;, &quot;green&quot;)) + 
  scale_size_continuous(range = c(6, 20), 
                        name = &quot;Standard Dev. 3y\n(annualized)&quot;) +
  annotation_custom(
    grob = tableGrob(bubexset[! bubexset$ItemType ==&quot;OMGI&quot;,
                              c(&quot;ItemId&quot;, &quot;FundName&quot;)],
    show.rownames = FALSE,
    show.box      = FALSE,
    gpar.coretext = gpar(fontsize = 7),
                     show.colnames = FALSE,),  
    xmin = 16, xmax = 25, ymin = 300, ymax = 350)

rm(bubexset)


</code></pre>

<p>The transformations applied are as follows:</p>

<ul>
<li>the best sellers have been dropped: there are instances where they are already included in the competitors set and their distance from the rest is typically quite big making them not so useful for the analysis</li>
<li>Once BS are dropped, the Ratio of NCCF of each fund vs. highest NCCF over 1 or 3 months (NCCF1mGBPmn and NCCF3mGBPmn) is computed (giving RatioToBS1m and RatioToBS3m) [this is dealt with at SQL level]</li>
<li>The performance of the funds (1y and 3y) are then divided by the performance of the best seller over 1m and 3m (giving Perf1y1mRatio, Perf3y1mRatio and perf1y3mRatio, perf3y3mRatio)  [this is dealt with at SQL level]</li>
<li>outliers are removed (outliers defined by |RatioToBS1m| or |RatioToBS3m| &gt; 10 and |PerformanceRatios| &gt; 3) </li>
<li>The group of funds observations where the number of competitors in the sample with valid data is less than 2 is dropped as well.</li>
</ul>

<p>The variables available for Panel B are:</p>

<pre><code class="r echo =FALSE, comment=&quot;&quot;">names(compdata)
</code></pre>

<pre><code class="r echo = FALSE, comment=&quot;&quot;">threshold &lt;- 10
compdata[! is.na(compdata$RatioToBS1m) &amp; 
           (compdata$RatioToBS1m &lt; -threshold | 
          compdata$RatioToBS1m &gt; threshold)
         , &quot;RatioToBS1m&quot;] &lt;- NA

compdata[! is.na(compdata$RatioToBS3m) &amp; 
           (compdata$RatioToBS3m &lt; -threshold | 
              compdata$RatioToBS3m &gt; threshold)
         , &quot;RatioToBS3m&quot;] &lt;- NA

#NA performing outliers
threshPerf &lt;- 3
compdata[! is.na(compdata$Perf3y1mRatio) &amp; 
           abs(compdata$Perf3y1mRatio) &gt; threshPerf
         , &quot;Perf3y1mRatio&quot;] &lt;- NA

compdata[! is.na(compdata$Perf3y3mRatio) &amp; 
           abs(compdata$Perf3y3mRatio) &gt; threshPerf
         , &quot;Perf3y3mRatio&quot;] &lt;- NA

compdata[! is.na(compdata$Perf1y1mRatio) &amp; 
           abs(compdata$Perf1y1mRatio) &gt; threshPerf
         , &quot;Perf1y1mRatio&quot;] &lt;- NA

compdata[! is.na(compdata$Perf1y3mRatio) &amp; 
           abs(compdata$Perf1y3mRatio) &gt; threshPerf
         , &quot;Perf1y3mRatio&quot;] &lt;- NA


#remove Best sellers
panelB &lt;- compdata[! compdata$ItemId %in% c(&#39;BS1m&#39;, &#39;BS3m&#39;), ]
#Filter out small samples
panelB &lt;- panelB[panelB$CompNo &gt; 2,]


</code></pre>

<p>The equivalent of chart above based this time on the NCCF, Performance and Volatility ratios would then be:</p>

<pre><code class="r echo = FALSE, fig.width=10, fig.height=8">bubexset &lt;- panelB[panelB$FundId == 314 &amp; 
                       panelB$RefDate == as.Date(&#39;2013-10-31&#39;), ]

ggplot(bubexset, aes(Perf3y3mRatio, 
                     RatioToBS3m,
                     size = StDev3y3mRatio, 
                     label=ItemId)) +
  geom_point(aes(colour = ItemType)) +
  geom_text(size=3) +
  xlab(&quot;Performance 3y (Ratio to BS)&quot;) + ylab(&quot;NCCF 3m (Ratio to BS)&quot;) +
  labs(title = bubexset[bubexset$ItemId == &#39;OMGI&#39;, &quot;FundName&quot;]) + 
  theme(plot.title = element_text(face = &quot;bold&quot;)) +
  scale_colour_manual(values = c(&quot;cyan&quot;, &quot;green&quot;)) + 
  scale_size_continuous(range = c(6, 20), 
                        name = &quot;Standard Dev. 3y\n(Ratio to BS)&quot;) 

</code></pre>

<p>Interpreting that chart (i.e. the ratio numbers) is intuitive as well: what the chart is showing is that while <em>Comp4</em> returned more than 20% on top of what the best seller (<em>OMGI</em> in this case) did over the last three months, the NCCF is about 54% of that fund.</p>

<pre><code class="r echo=FALSE, comment=&quot;&quot;">print(bubexset[, c(&quot;ItemId&quot;, &quot;RatioToBS3m&quot;, &quot;Perf3y3mRatio&quot;,
                   &quot;StDev3y3mRatio&quot;)])
rm(bubexset)
</code></pre>

<h3>Results</h3>

<pre><code class="r echo=FALSE">extremeThresh &lt;- 0.15
panelA_extr &lt;- panelA[panelA$Rank1y &lt; extremeThresh | 
                          panelA$Rank1y &gt; 1- extremeThresh, ]

#normal performers
panelA_mid &lt;- panelA[panelA$Rank1y &gt; extremeThresh &amp; 
                       panelA$Rank1y &lt; 1- extremeThresh, ]

</code></pre>

<h4>Panel A analysis</h4>

<p>The analysis of panel A dataset explore the relationship between monthly performance data and the NCCF.</p>

<p>The starting point is an all-in regression where all the variable are thrown in.
Starting from there, a stepwise algorithm [2] is used to get to the best model.
The result is as follows:</p>

<pre><code class="r echo = FALSE, comment=&quot;&quot;">modelKitchenSink &lt;- lm(NCCF ~
                         AbsPerf3m +
                         AbsPerf6m +
                         AbsPerf1y +
                         AbsPerf2y +
                         AbsPerf3y +
                         RelPerf3m +
                         RelPerf6m +
                         RelPerf1y +
                         RelPerf2y +
                         RelPerf3y +
                         Rank3m +
                         Rank6m +
                         Rank1y +
                         Rank2y +
                         Rank2y +
                         Rank3y,
                       data = panelA, na.action = na.omit)
#summary(modelKitchenSink)

model &lt;- step(modelKitchenSink, direction=&quot;both&quot;, trace = 0)

summary(model)
confint(model)

rm(modelKitchenSink)

</code></pre>

<p>This model concludes that, statistically, <em>RelPerf3y</em> has a positive relationship with NCCF (<em>coeteris paribus</em> for an extra 1% of relative performance the fund, on average, gets an extra 0.20% of NCCF) and <em>Rank1y</em> (<em>coeteris paribus</em> for an extra drop in percentile ranking of 1% the fund, on average, gets an extra 0.04% of NCCF).</p>

<p>While the intuition seems to be correct it is also true that, statistically, the regression is not explaining the variation in NCCF in any meaningful way (as the Adjusted R-squared at 0.13 shows).</p>

<p>Graphically this can be shown looking at the chart plotting NCCF against those two &ldquo;best&rdquo; explaining variables. While at that the sample was also divided by vehicle splitting domestic (OEIC) and offshore (UCITS4) UCITS funds.</p>

<pre><code class="r echo = FALSE, fig.width=10, fig.height=8">source(&quot;multiplot.R&quot;)

p1 &lt;- ggplot(na.omit(panelA[panelA$Vehicle == &quot;OEIC&quot; | panelA$Vehicle == &quot;UCITS4&quot;, ]
                     [,c(&quot;NCCF&quot;, &quot;RelPerf3y&quot;, &quot;Vehicle&quot;)]), 
             aes(x=RelPerf3y, y=NCCF)) + 
  geom_point(shape=1) + 
  geom_smooth(method= &quot;lm&quot;, se = TRUE) +
  facet_wrap( ~ Vehicle, nrow=2) + 
  theme(plot.title = element_text(lineheight=.8, face=&quot;bold&quot;, size = 10)) +
  ggtitle(&quot;Monthly NCCF* by Relative performance (3y) \n&quot;) +
  #theme(legend.title=element_blank()) +
  scale_x_continuous(labels=percent) +
  scale_y_continuous(labels=percent) +
  ylab(&quot;NCCF&quot;) +
  xlab(&quot;3y Relative Performance&quot;) 

p2 &lt;- ggplot(na.omit(panelA[panelA$Vehicle == &quot;OEIC&quot; | panelA$Vehicle == &quot;UCITS4&quot;, ]
                     [,c(&quot;NCCF&quot;, &quot;Rank1y&quot;, &quot;Vehicle&quot;)]), 
             aes(x=Rank1y, y=NCCF)) + 
  geom_point(shape=1) + 
  geom_smooth(method= &quot;lm&quot;, se = TRUE) +
  facet_wrap( ~ Vehicle, nrow=2) + 
  theme(plot.title = element_text(lineheight=0.8, face=&quot;bold&quot;, size = 10)) +
  ggtitle(&quot;Monthly NCCF* by percentile ranking (1y) \n&quot;) +
  #theme(legend.title=element_blank()) +
  scale_x_continuous(labels=percent) +
  scale_y_continuous(labels=percent) +
  ylab(&quot;NCCF&quot;) +
  xlab(&quot;1y Percentile ranking&quot;) 

multiplot(p1, p2, cols = 2)

</code></pre>

<p>It&#39;s fairly clear that the linkage between those two variable is not very strong.</p>

<p>Another option explored was to check if some strong relationship could be found for extreme performers (those in the top 15% or bottom 15% of the their sector table).
Again there is no strong evidence that might lead to think that if a fund is an extreme performer it might get particular treatment from the clients: a bottom of the league performer can easily get away with it; a top performer might be commercially disappointed.</p>

<pre><code class="r echo = FALSE, fig.width=10, fig.height=8">p1 &lt;- ggplot(na.omit(panelA_extr[panelA_extr$Vehicle == &quot;OEIC&quot; | panelA_extr$Vehicle == &quot;UCITS4&quot;, ]
                     [,c(&quot;NCCF&quot;, &quot;Rank1y&quot;, &quot;Vehicle&quot;)]), 
             aes(x=Rank1y, y=NCCF)) + 
  geom_point(shape=1) + 
  geom_smooth(method= &quot;lm&quot;, se = TRUE) +
  facet_wrap( ~ Vehicle, nrow=2) + 
  theme(plot.title = element_text(lineheight=.8, face=&quot;bold&quot;, size = 10)) +
  ggtitle(&quot;Monthly NCCF* by peer rank (1y) \n (percentile &lt; 15% or &gt; 85%) \n&quot;) +
  #theme(legend.title=element_blank()) +
  scale_x_continuous(labels=percent) +
  scale_y_continuous(labels=percent) +
  ylab(&quot;NCCF&quot;) +
  xlab(&quot;Peer rank&quot;) 

p2 &lt;- ggplot(na.omit(panelA_mid[panelA_mid$Vehicle == &quot;OEIC&quot; | panelA_mid$Vehicle == &quot;UCITS4&quot;, ]
                     [,c(&quot;NCCF&quot;, &quot;Rank1y&quot;, &quot;Vehicle&quot;)]), 
             aes(x=Rank1y, y=NCCF)) + 
  geom_point(shape=1) + 
  geom_smooth(method= &quot;lm&quot;, se = TRUE) +
  facet_wrap( ~ Vehicle, nrow=2) + 
  theme(plot.title = element_text(lineheight=.8, face=&quot;bold&quot;, size = 10)) +
  ggtitle(&quot;Monthly NCCF* by peer rank (1y) \n (percentile &gt; 15% or &lt; 85%) \n&quot;) +
  #theme(legend.title=element_blank()) +
  scale_x_continuous(labels=percent) +
  scale_y_continuous(labels=percent) +
  ylab(&quot;NCCF&quot;) +
  xlab(&quot;Peer rank&quot;) 

multiplot(p1, p2, cols = 2)

</code></pre>

<h4>Lagging panel A variables</h4>

<p>An obvious push-back is: it&#39;s yesterday performance determining today NCCF. It makes sense trying that with short term performance variables (1m and 3m). 
It doesn&#39;t make much sense if you think that it is long term performance driving today sales (lagging 1y or 3y performance numbers vs. monthly NCCF is not a good idea).</p>

<p>Again the methodology is the same: we start with an &ldquo;all-in&rdquo; model where all 1m and 3m performance variable have been lagged for 1, 2 and 3 periods (that is monthly \( NCCF(T) \) is explained simultaneously by \( AbsPerfXm(T-i) \), \( RelPerfXm(T-i) \), \( RankXm(T-i) \) where \( X \) is equal to 1 and 3 and \( i \) is equal to 1, 2, 3) and then the stepwise algorithm returns the best model.</p>

<pre><code class="r echo=FALSE, comment=&quot;&quot;">panelSet &lt;- na.omit(panelA[, c(&quot;FundCode&quot;
                         , &quot;RefDate&quot;
                         , &quot;NCCF&quot;
                         , &quot;AbsPerf1m&quot;
                         , &quot;RelPerf1m&quot;
                         , &quot;AbsPerf3m&quot;
                         , &quot;RelPerf3m&quot;
                         , &quot;Rank3m&quot;                               
                         , &quot;Rank1m&quot;
                         , &quot;Rank1y&quot;
                         , &quot;RelPerf3y&quot;)])

pdataSet &lt;- pdata.frame(panelSet
                        , index = c(&quot;FundCode&quot;, &quot;RefDate&quot;)
                        , drop.index = FALSE
                        , row.names = TRUE)
rm(panelSet)

#head(pdataSet)
#length(unique(pdataSet$FundCode))

laggedMod &lt;- lm(NCCF ~ 
                + lag(pdataSet$RelPerf1m, 1)
                + lag(pdataSet$RelPerf1m, 2)
                + lag(pdataSet$RelPerf1m, 3)
                + lag(pdataSet$AbsPerf1m, 1)
                + lag(pdataSet$AbsPerf1m, 2)
                + lag(pdataSet$AbsPerf1m, 3)
                + lag(pdataSet$Rank1m, 1)
                + lag(pdataSet$Rank1m, 2)
                + lag(pdataSet$Rank1m, 3)
                + lag(pdataSet$RelPerf3m, 1)
                + lag(pdataSet$RelPerf3m, 2)
                + lag(pdataSet$RelPerf3m, 3)
                + lag(pdataSet$AbsPerf3m, 1)
                + lag(pdataSet$AbsPerf3m, 2)
                + lag(pdataSet$AbsPerf3m, 3)
                + lag(pdataSet$Rank3m, 1)
                + lag(pdataSet$Rank3m, 2)
                + lag(pdataSet$Rank3m, 3)
                , data=pdataSet, na.action=na.omit)


#summary(laggedMod)
finalLags &lt;- step(laggedMod, direction=&quot;both&quot;, trace = 0)
summary(finalLags)
rm(laggedMod)

</code></pre>

<p>Again the coefficients with some significance have the expected sign (Rank1m<sup>T-2</sup> , Rank1m<sup>T-3</sup> , Relative performance<sup>T-3</sup> ) but the overall quality of the regression is statistically weak.</p>

<p>Graphically you get to the same conclusions:</p>

<pre><code class="r echo=FALSE">par(mfrow = c(2,2))
#plot(pdataSet$RelPerf3m, pdataSet$NCCF)
plot(lag(pdataSet$Rank1m, 2), pdataSet$NCCF)
plot(lag(pdataSet$Rank1m, 3), pdataSet$NCCF)
plot(lag(pdataSet$RelPerf3m, 3), pdataSet$NCCF)
plot(lag(pdataSet$RelPerf1m, 3), pdataSet$NCCF)
par(mfrow = c(1,1))

</code></pre>

<h4>Panel B analysis</h4>

<p>The purpose of the panel B analysis is to check if that relationship which is not strong in the OMGI range is any more significant if we use data for other competitors.
The variable used in this case have been explained above.</p>

<p>The pictures below already show we can&#39;t get very high hopes even with this second data set.</p>

<pre><code class="r echo = FALSE, fig.width=10, fig.height=10">par(mar = c(4,4,2,2))
par(mfrow = c(2,2))
plot(panelB$Perf1y1mRatio, panelB$RatioToBS1m, 
     col=rgb(0,100,0,50,maxColorValue=255), pch=16,
     xlab = &quot;1y perf. ratio to 1m best NCCF 1y perf.&quot;,
     ylab = &quot;1m NCCF ratio to 1m best NCCF&quot;, 
     cex.lab = 0.8,
     cex.axis = 0.8, 
     bty=&quot;n&quot;)
mtext(&quot;NCCF to best seller (among selected competitors) vs. performance ratios&quot;, 
      side = 3, adj = 0, cex = 0.7, line = 1, font = 4)
plot(panelB$Perf3y1mRatio, panelB$RatioToBS1m, 
     col=rgb(0,100,0,50,maxColorValue=255), pch=16,
     xlab = &quot;3y perf. ratio to 1m best NCCF 3y perf.&quot;,
     ylab = &quot;1m NCCF ratio to 1m best NCCF&quot;, 
     cex.lab = 0.8,
     cex.axis = 0.8, 
     bty=&quot;n&quot;)
plot(panelB$Perf1y3mRatio, panelB$RatioToBS3m, 
     col=rgb(0,100,0,50,maxColorValue=255), pch=16,
     xlab = &quot;1y perf. ratio to 1m best NCCF 1y perf.&quot;,
     ylab = &quot;3m NCCF ratio to 3m best NCCF&quot;, 
     cex.lab = 0.8,
     cex.axis = 0.8, 
     bty=&quot;n&quot;)
plot(panelB$Perf3y3mRatio, panelB$RatioToBS3m, 
     col=rgb(0,100,0,50,maxColorValue=255), pch=16, 
     xlab = &quot;3y perf. ratio to 3m best NCCF 3y perf.&quot;,
     ylab = &quot;3m NCCF ratio to 3m best NCCF&quot;, 
     cex.lab = 0.8,
     cex.axis = 0.8, 
     bty=&quot;n&quot;)
par(mar = c(5,4,4,2) + 0.1)
par(mfcol = c(1,1))

</code></pre>

<p>Numerically we have </p>

<pre><code class="r echo=FALSE, comment=&quot;&quot;">model1m &lt;- lm(RatioToBS1m ~
                Perf3y1mRatio
              + Perf1y1mRatio
              + StDev3y1mRatio
              + StDev1y1mRatio
              , data = panelB)
summary(model1m)

model3m &lt;- lm(RatioToBS3m ~
                Perf3y3mRatio
              + Perf1y3mRatio
              + StDev3y3mRatio
              + StDev1y3mRatio
              , data = panelB)
summary(model3m)

</code></pre>

<p>Given the reduced number of variables there is no need to employ the stepwise algorithm. And given the length of the performance variable used, there is no need to lag them.<br/>
The overall sentence is, again: no relationship.</p>

<h3>Conclusions</h3>

<p>The results show that, while intellectually and financially rewarding for the fund manager, fund performance doesn&#39;t automatically translate into commercial success for the asset management firm running them.<br/>
This is largely as expected: retail clients typically receive very poor information about how their money is doing and (even more important) how their money could do in the future depending on market circumstances.</p>

<p>Their typical fund allocation is sticky and there is the obvious psychological obstacle of taking losses and practical switching costs affecting their decisions.</p>

<p>If it&#39;s not performance that matters, what is?<br/>
Distribution activity seems to be the obvious answer.
Funds are created and sold on the back of institutional documents like KIIDS or uninformative fact-sheets that might be delievered with a considerable delay.
Regulators are primarily to blame for this but it&#39;s the author opinion it&#39;s on the asset managers industry to try and pull their act together.</p>

<p>What can be done then? This is a short list of suggestions:</p>

<ul>
<li>Structure the Investment Manager operation toward the delivery of factual information about fund performances and portfolios characteristics. This could then allow the asset manager to</li>
<li>provide a strong linkage between client money and products, hopefully delivering statistics about client performance linked to products performance</li>
<li>make sure the adequate level of governance (beyond the one required by the regulator) is properly addressed in all the relevant aspects. That is: make sure that a clear definition of each product is available by maintaining a structure that enable the unequivocal listing of: 

<ul>
<li>risk/reward objectives</li>
<li>investment restrictions</li>
<li>portfolio management style</li>
</ul></li>
<li>pro-actively engage with the clients on the basis of that information</li>
<li>potentially increasing the level of transparency around product governance items listed above</li>
<li>explore new channels to convey that information (and, possibly, have some information back): social media is the obvious candidate.</li>
</ul>

<p>This could then provide a better framework to explain why there is a good reason your products are better than others: effectively this could create a proper brand and not only a name.</p>

<p>It has also to be considered that this better level of service might also lead to better pricing power: in a commoditized industry (also considering the effect of RDR) this could be crucial.</p>

<p>Talking about the products way beyond the basic regulatory requirements could be the key: the successful product will be the one with good stories to tell, not the one returning the best.</p>

<h3>References</h3>

<p>[1] <a href="http://en.wikipedia.org/wiki/Stepwise_regression">http://en.wikipedia.org/wiki/Stepwise_regression</a> (the Akaike information criterion - AIC - is used; both directions)</p>

</body>

</html>

